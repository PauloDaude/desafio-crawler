# Desafio Crawler

## ðŸŒŸ VisÃ£o Geral

Este projeto se trata de um crawler (web scraper) que coleta informaÃ§Ãµes de laptops Lenovo de um site de e-commerce, disponibilizando os dados atravÃ©s de uma API REST simples.

## âœ¨ Funcionalidades

- **Scraping recursivo** de mÃºltiplas pÃ¡ginas
- **Filtro automÃ¡tico** por laptops Lenovo
- **OrdenaÃ§Ã£o por preÃ§o** (do mais barato para o mais caro)
- **API REST** com endpoint `/laptops`
- **Tipagem TypeScript** robusta

## ðŸ›  Tecnologias Utilizadas

| Tecnologia | DescriÃ§Ã£o                                  |
| ---------- | ------------------------------------------ |
| Node.js    | Ambiente de execuÃ§Ã£o JavaScript (v20.11.1) |
| TypeScript | Tipagem estÃ¡tica (v^5.8.2)                 |
| Express    | Framework web para a API (v^5.1.0)         |
| Axios      | Cliente HTTP para requests (v^1.8.4)       |
| JSDOM      | ImplementaÃ§Ã£o DOM para Node.js (v^26.0.0)  |

## ðŸš€ Como Executar

### PrÃ©-requisitos

- Node.js (v18+)
- npm ou yarn

### InstalaÃ§Ã£o

```bash
git clone https://github.com/PauloDaude/desafio-crawler.git
cd desafio-crawler
npm install
```

### ExecuÃ§Ã£o

```bash
npm start
```

A API estarÃ¡ disponÃ­vel em: `http://localhost:3000/laptops`

## ðŸ“Š Estrutura do Projeto

```
desafio-crawler/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.ts            # ConfiguraÃ§Ã£o do servidor Express
â”‚   â”œâ”€â”€ scraper.ts        # LÃ³gica principal de scraping
â”‚   â””â”€â”€ scraper-utils.ts  # FunÃ§Ãµes auxiliares e tipagem
â”œâ”€â”€ dist/                 # Arquivos compilados (gerado automaticamente)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ package.json
â”œâ”€â”€ README.md
â””â”€â”€ tsconfig.json
```

## ðŸ“¡ Endpoint da API

### `GET /laptops`

Retorna todos os laptops Lenovo ordenados por preÃ§o

**Exemplo de Response:**

```json
[
  {
    "title": "Lenovo IdeaPad 3",
    "price": "$599.99",
    "description": "15.6 FHD, Ryzen 5, 8GB RAM...",
    "imgUrl": "https://webscraper.io/images/lenovo.jpg",
    "rating": "6 reviews"
  },
  ...
]
```
